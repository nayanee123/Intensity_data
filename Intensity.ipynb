{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac2d9553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  intensity\n",
      "0  Wants to know how the hell I can remember word...  happiness\n",
      "1  Love is a long sweet dream & marriage is an al...  happiness\n",
      "2  The world could be amazing when you are slight...  happiness\n",
      "3  My secret talent is getting tired without doin...  happiness\n",
      "4  Khatarnaak Whatsapp Status Ever… Can\\’t talk, ...  happiness\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the CSV files to load\n",
    "csv_files = ['happiness.csv', 'angriness.csv', 'sadness.csv']\n",
    "\n",
    "# Load and concatenate all CSV files into a single DataFrame\n",
    "data_frames = [pd.read_csv(file) for file in csv_files]\n",
    "data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the concatenated DataFrame\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3364f032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['content', 'intensity'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7306ee1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  intensity\n",
      "0  Wants to know how the hell I can remember word...  happiness\n",
      "1  Love is a long sweet dream & marriage is an al...  happiness\n",
      "2  The world could be amazing when you are slight...  happiness\n",
      "3  My secret talent is getting tired without doin...  happiness\n",
      "4  Khatarnaak Whatsapp Status Ever… Can\\’t talk, ...  happiness\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the directory where the CSV files are stored\n",
    "data_dir = 'Intensity_data'\n",
    "\n",
    "# Define the CSV files to load (include the directory path)\n",
    "csv_files = [os.path.join('happiness.csv'), os.path.join('angriness.csv'), os.path.join('sadness.csv')]\n",
    "\n",
    "# Load and concatenate all CSV files into a single DataFrame\n",
    "data_frames = []\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        data_frames.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "if len(data_frames) == 0:\n",
    "    raise ValueError(\"No data loaded. Check the file paths and formats.\")\n",
    "\n",
    "data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the concatenated DataFrame\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dd6d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Function to clean the text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\d', ' ', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Ensure the clean_text function is defined before this step\n",
    "# Apply text cleaning to the 'content' column\n",
    "data['cleaned_text'] = data['content'].apply(clean_text)\n",
    "\n",
    "# Encode the labels in the 'intensity' column\n",
    "label_encoder = LabelEncoder()\n",
    "data['intensity_label'] = label_encoder.fit_transform(data['intensity'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_text'], data['intensity_label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Save label encoder for future use\n",
    "with open('label_encoder.pkl', 'wb') as le_file:\n",
    "    pickle.dump(label_encoder, le_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9262a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering :\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Save vectorizer for future use\n",
    "with open('vectorizer.pkl', 'wb') as vec_file:\n",
    "    pickle.dump(vectorizer, vec_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e715171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Model Selection and Training :\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Save the trained model for future use\n",
    "with open('model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4df6544e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 73.77%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   angriness       0.76      0.78      0.77       133\n",
      "   happiness       0.76      0.72      0.74       156\n",
      "     sadness       0.68      0.71      0.69       119\n",
      "\n",
      "    accuracy                           0.74       408\n",
      "   macro avg       0.74      0.74      0.74       408\n",
      "weighted avg       0.74      0.74      0.74       408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Model Evaluation :\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display classification report\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84f5c252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "#  Hyperparameter Tuning (Optional) :\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=LogisticRegression(), param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Use the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Save the best model\n",
    "with open('best_model.pkl', 'wb') as best_model_file:\n",
    "    pickle.dump(best_model, best_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2b64940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the saved model\n",
    "with open('best_model.pkl', 'rb') as best_model_file:\n",
    "    best_model = pickle.load(best_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b8c81ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the saved TfidfVectorizer\n",
    "with open('vectorizer.pkl', 'rb') as vec_file:\n",
    "    vectorizer = pickle.load(vec_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4c53b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Step 1: Load the saved TfidfVectorizer\n",
    "with open('vectorizer.pkl', 'rb') as vectorizer_file:\n",
    "    vectorizer = pickle.load(vectorizer_file)\n",
    "\n",
    "# Step 2: Load the saved LogisticRegression model\n",
    "with open('best_model.pkl', 'rb') as model_file:\n",
    "    best_model = pickle.load(model_file)\n",
    "\n",
    "# Step 3: Your new text data\n",
    "new_data = [\"This is a sample text that I want to classify.\"]\n",
    "\n",
    "# Step 4: Transform the new text data using the vectorizer\n",
    "new_data_tfidf = vectorizer.transform(new_data)\n",
    "\n",
    "# Step 5: Use the loaded model to make a prediction\n",
    "predictions = best_model.predict(new_data_tfidf)\n",
    "\n",
    "# Step 6: Print the prediction\n",
    "print(\"Predicted class:\", predictions[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
